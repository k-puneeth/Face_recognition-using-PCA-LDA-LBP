# -*- coding: utf-8 -*-
"""assignment3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14fJiHIKkWq49POh3JUNQTspMA6b99Vk8
"""

import numpy as np
import cv2
from matplotlib import pyplot as plt
import glob
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from scipy.spatial import distance
from sklearn.metrics import accuracy_score
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from skimage import feature
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.svm import SVC
from sklearn.utils import shuffle
# !pip install face_recognition
import face_recognition
import argparse

from google.colab import drive
drive.mount('/content/drive')

# images = []
# for filename in glob.glob('../content/drive/My Drive/AVR_data/**/*.jpg', recursive=True):
#     images.append(filename)
# for filename in glob.glob('../content/drive/My Drive/AVR_data/**/*.JPG', recursive=True):
#     images.append(filename)
# for filename in glob.glob('../content/drive/My Drive/AVR_data/**/*.jpeg', recursive=True):
#     images.append(filename)
# print(len(images))

folders = []
for filename in glob.glob('../content/drive/My Drive/AVR_data/*'):
    folders.append(filename)
len(folders)

def train_test_split(lst, percent, j):
#   random.seed(1999)
#   random.shuffle(lst)
  cut = int(len(lst)*percent)
  labels = [j]*len(lst)
  return lst[:cut], lst[cut:], labels[:cut], labels[cut:]

# imagenames2 = []
train_image_names = []
test_image_names = []
train_labels = []
test_labels = []
j = 0
for folder in folders:
  imagenames2 = []
  for filename in glob.glob(folder + '/*.jpg'):
    imagenames2.append(filename)
#     lables.append(j)
  for filename in glob.glob(folder + '/*.JPG'):
    imagenames2.append(filename)
#     lables.append(j)
  for filename in glob.glob(folder + '/*.jpeg'):
    imagenames2.append(filename)
#     lables.append(j)
  tra, tes, tra_labels, tes_labels = train_test_split(imagenames2, 0.8, j)
  train_image_names.extend(tra)
  test_image_names.extend(tes)
  train_labels.extend(tra_labels)
  test_labels.extend(tes_labels)
  j =  j + 1

# labels = []
# images_2 = []
# i = 0
# for folder in folders:
#   for filename in glob.glob(folder+ '/*.jpg'):
#     images_2.append(filename)
#     labels.append(i)
#   for filename in glob.glob(folder+ '/*.JPG'):
#     images_2.append(filename)
#     labels.append(i)
#   for filename in glob.glob(folder+ '/*.jpeg'):
#     images_2.append(filename)
#     labels.append(i)
#   i = i + 1

# random.seed(55)
shuffle(train_image_names, train_labels);
# random.shuffle(train_labels)

train_images = []
test_images = []
imgs = []
for image in train_image_names:
    img = cv2.imread(image,1)
    train_images.append(img)
    imgs.append(img)
for image in test_image_names:
    img = cv2.imread(image,1)
    test_images.append(img)
    imgs.append(img)
print(len(train_images))

# imgs1=imgs

# !wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye.xml -P drive/My\ Drive
# !wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml -P drive/My\ Drive
# !wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt.xml -P drive/My\ Drive
# !wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt2.xml -P drive/My\ Drive4
# !wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye_tree_eyeglasses.xml -P drive/My\ Drive
# !wget https://raw.githubusercontent.com/opencv/opencv_contrib/master/modules/face/data/cascades/haarcascade_mcs_nose.xml -P drive/My\ Drive
# !wget https://raw.githubusercontent.com/sightmachine/SimpleCV/master/SimpleCV/Features/HaarCascades/mouth.xml -P drive/My\ Drive
# !wget https://raw.githubusercontent.com/voidstellar/haar-cascade-files/master/haarcascade_mcs_mouth.xml -P drive/My\ Drive

cascades_path = 'drive/My Drive/'
# # face_cascade = cv2.CascadeClassifier(cascades_path + 'haarcascade_frontalface_alt.xml')
face_cascade = cv2.CascadeClassifier(cascades_path + 'haarcascade_frontalface_default.xml')
# # eye_cascade = cv2.CascadeClassifier(cascades_path + 'haarcascade_eye.xml')
eye_cascade = cv2.CascadeClassifier(cascades_path + 'haarcascade_eye_tree_eyeglasses.xml')

nose_cascade = cv2.CascadeClassifier(cascades_path + 'haarcascade_mcs_nose.xml')

# mouth_cascade = cv2.CascadeClassifier(cascades_path + 'haarcascade_mouth.xml')

mouth_updated_cascade = cv2.CascadeClassifier(cascades_path + 'haarcascade_mcs_mouth.xml')

def make_oval_image(imgs_lst, labels_lst, face_cascade, eye_cascade):
  roi_imgs = []
  updated_labels = []
  for i in range(len(imgs_lst)):
    gray = cv2.cvtColor(imgs_lst[i],cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    for (x,y,w,h) in faces:
      img = cv2.rectangle(imgs_lst[i],(x,y),(x+w,y+h),(255,0,0),2)
      mask = np.zeros_like(imgs_lst[i])
      rows,cols,_ = mask.shape
      if (w>h):
        mask=cv2.ellipse(mask,(int((x+(x+w))/2),int((y+(y+h))/2)),(int(w/2),int(h/2)),0,0,360,(255,255,255),-1,8,0) 
      else:
        mask = cv2.ellipse(mask,(int((x+(x+w))/2),int((y+(y+h))/2)),(int(h/2),int(w/2)),0,0,360,(255,255,255),-1,8,0)
      roi_ellipse = np.bitwise_and(imgs_lst[i],mask)
      pts1 = np.float32([[x,y],[x,y+h],[x+w,y],[x+w,y+h]])
      pts2 = np.float32([[0,0],[0,int(cols/2)],[int(rows/2),0],[int(rows/2),int(cols/2)]])
      M = cv2.getPerspectiveTransform(pts1,pts2)
      dst = cv2.warpPerspective(roi_ellipse,M,(int(cols/2),int(rows/2)))
      roi_gray = gray[y:y+h, x:x+w]
      roi_color = img[y:y+h, x:x+w]
      eyes = eye_cascade.detectMultiScale(roi_gray)
      nose = nose_cascade.detectMultiScale(roi_gray)
#       mouth = mouth_cascade.detectMultiScale(roi_gray)
      mouth_updated = mouth_updated_cascade.detectMultiScale(roi_gray) 
      for (nx, ny, nw, nh) in nose:
        cv2.rectangle(roi_color,(nx,ny),(nx+nw,ny+nh),(0,255,0),2)
#       for (mx, my, mw, mh) in mouth_updated:
#         cv2.rectangle(roi_color,(mx,my),(mx+mw,my+mh),(0,255,0),2)
      for (ex,ey,ew,eh) in eyes:
        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)
        roi_eye_gray = roi_gray[ey:ey+eh, ex:ex+ew]
        roi_eye_color = roi_color[ey:ey+eh, ex:ex+ew]
        # convert image to grayscale image
#         gray_image = cv2.cvtColor(roi_eye_color, cv2.COLOR_BGR2GRAY)

        # convert the grayscale image to binary image
        ret,thresh = cv2.threshold(roi_eye_gray,20,255,0)

        thresh_inv = cv2.bitwise_not(thresh)

        # calculate moments of binary image
        M = cv2.moments(thresh)

        # calculate x,y coordinate of center
        if M["m00"] != 0:
          cX = int(M["m10"] / M["m00"])
          cY = int(M["m01"] / M["m00"])
        else:
          cX, cY = 0, 0
        # put text and highlight the center
        cv2.circle(roi_eye_color, (cX, cY), 5, (0, 0, 0), -1)
        cv2.putText(roi_eye_color, "centroid", (cX - 25, cY - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
      count = 0
      roi_imgs.append(dst)
      updated_labels.append(labels_lst[i])
      
  return roi_imgs, updated_labels


# display the image
# cnvt_img = cv2.cvtColor(dst,cv2.COLOR_BGR2RGB)
# plt.imshow(cnvt_img)
# plt.xticks([]),plt.yticks([])
# plt.show()

tmp_img = []
tmp_img.append(train_images[0])
roi_train_imgs, roi_train_labels = make_oval_image(tmp_img, train_labels, face_cascade, eye_cascade)
# roi_test_imgs, roi_test_labels = make_oval_image(test_images, test_labels, face_cascade, eye_cascade)
cnvt_img = cv2.cvtColor(roi_train_imgs[0],cv2.COLOR_BGR2RGB)
plt.imshow(cnvt_img)
plt.xticks([]),plt.yticks([])
plt.show()

len(roi_train_imgs)

"""trial = cv2.cvtColor(imgs[0],cv2.COLOR_BGR2RGB)
plt.imshow(trial)
plt.xticks([]),plt.yticks([])
plt.show()
"""

# shuffler = list(range(858))
# shuffle(shuffler)
# # len(shuffler)

# shuffler_images = []
# shuffler_labels = []
# for i in range(len(shuffler)):
#   shuffler_images.append(imgs[shuffler[i]])
#   shuffler_labels.append(labels[shuffler[i]])
# print(len(shuffler_images))
# print(len(shuffler_labels))

# train_images = shuffler_images[:600]
# train_labels = shuffler_labels[:600]
# test_images = shuffler_images[600:]
# test_labels = shuffler_labels[600:]

# plt.imshow(test_images[0])

def get_vector_matrix(mat):
  res_imgs = []
  vec_mat = []
  for image in mat:
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    res_imgs.append(cv2.resize(image, (256, 256)))
  for image in res_imgs:
    vec_mat.append(image.ravel())
  vec_mat = np.array(vec_mat)
  print(vec_mat.shape)
  vec_mat = vec_mat.T
  print(vec_mat.shape)
  return vec_mat

# res_imgs = []
# for image in imgs:
#   image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#   res_imgs.append(cv2.resize(image, (256, 256)))
# len(res_imgs)

# res_imgs

# print(len(res_imgs))
# # train = []
# for image in res_imgs:
#   train.append(image.ravel())

# train = np.array(train)
# train = train.T
# train.shape
x_train = get_vector_matrix(roi_train_imgs)
# print(x_train[400][45])
x_test = get_vector_matrix(roi_test_imgs)
# print(x_test[200][45])

train_mean = np.mean(x_train,axis=0)
print(train_mean.shape)
test_mean = np.mean(x_test,axis=0)
# print(test_mean)

def get_data_matrix(mat, mean):
  mat1 = []
  for i in range(mat.shape[0]):
    mat1.append(mat[i][:] - mean)
  return np.array(mat1)

train_data = get_data_matrix(x_train, train_mean)
# print(train_data[400][45])
test_data = get_data_matrix(x_test, test_mean)
# print(test_data[200][45])

train_data.shape

C_train = np.matmul(train_data.T, train_data)
# C_test = np.matmul(test_data.T, test_data)
# C.shape
C_train.shape

values_train, vectors_train = np.linalg.eig(C_train)
# values_test, vectors_test = np.linalg.eig(C_test)
vectors_train.shape
# vectors_test.shape

"""original_e_train = np.matmul(train_data.T,vectors_train)"""

e_train = np.matmul(train_data,vectors_train)
print(e_train.shape)
# e_test = np.dot(test_data,vectors_test)

w_train = np.matmul(e_train.T,x_train)
w_test = np.matmul(e_train.T,x_test)

def nearest(point):
  mini = 1e20
  pos= 0
  for i in range(w_train.shape[1]):
    dist=distance.euclidean(w_train[:,i],point)
    if(dist<mini):
      mini = dist
      pos=i
  return train_labels[pos]

print(w_train.shape)
print(w_test.shape)

pred_labels=[]
for i in range(w_test.shape[1]):
  pred_labels.append(nearest(w_test[:,i]))

accuracy_score(pred_labels,roi_test_labels)

print(pred_labels)
print(test_labels)

# x_train[1]

lda_clf = LinearDiscriminantAnalysis(n_components = 200)

lda_clf.fit(x_train.T,train_labels)

lda_pred = lda_clf.predict(x_test.T)

accuracy_score(lda_pred,test_labels)

# lda_pred

def describe(image,numPoints,radius,eps=1e-7):
  lbp = feature.local_binary_pattern(image,numPoints,radius,method='uniform')
  (hist,_) = np.histogram(lbp.ravel(),bins=np.arange(0,numPoints+3),range=(0,numPoints+2))
  hist = hist.astype('float')
  hist /= (hist.sum()+eps)
  return hist

histograms =[]
for image in train_images:
  gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
  histograms.append(describe(gray,24,8))

lr_clf = LogisticRegression(random_state=42,solver='lbfgs',multi_class='multinomial').fit(histograms,train_labels)

test_hists = []
for image in test_images:
  gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
  test_hists.append(describe(gray,24,8))

lr_pred = lr_clf.predict(test_hists)

accuracy_score(lr_pred,test_labels)

linsvm_clf = LinearSVC(C=100.0,random_state=42).fit(histograms,train_labels)

linsvc_pred = linsvm_clf.predict(test_hists)

accuracy_score(linsvc_pred,test_labels)

svc = SVC(gamma='auto',C=100.0,random_state=42).fit(histograms,train_labels)

svc_pred = svc.predict(test_hists)

accuracy_score(svc_pred,test_labels)

knownEncodings= []
knownLabels = []
for i in range(len(train_images)):
  rgb = cv2.cvtColor(train_images[i],cv2.COLOR_BGR2RGB)
  boxes = face_recognition.face_locations(rgb)
  encodings = face_recognition.face_encodings(rgb,boxes)
  for encoding in encodings:
    knownEncodings.append(encoding)
    knownLabels.append(train_labels[i])

# len(knownLabels)

unknownEncodings = []
openface_labels = []
openface_test_labels = []
for i in range(len(test_images)):
  rgb = cv2.cvtColor(test_images[i],cv2.COLOR_BGR2RGB)
  boxes = face_recognition.face_locations(rgb)
  encodings = face_recognition.face_encodings(rgb,boxes)
  for encoding in encodings:
    matches = face_recognition.compare_faces(knownEncodings,encoding)
    if True in matches:
      matchedIdxs = [j for (j,b) in enumerate(matches) if b]
      counts = {}
      for j in matchedIdxs:
        test_name = knownLabels[j]
        counts[test_name] = counts.get(test_name,0)+1
      label = max(counts,key=counts.get)
    openface_labels.append(label)
    openface_test_labels.append(test_labels[i])

# print(len(openface_labels))
# len(openface_test_labels)

accuracy_score(openface_labels,openface_test_labels)

